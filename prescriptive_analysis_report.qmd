---
title: "PlaylistPro Retention Optimization: Prescriptive Analysis"
subtitle: "MILP Optimization Model"
author: "Satkar Karki, Business Analytics Team"
date: "November 5, 2025"
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: false
    colorlinks: true
    geometry:
      - top=0.75in
      - bottom=0.75in
      - left=0.75in
      - right=0.75in
    fig-width: 7
    fig-height: 4.5
    keep-tex: false
    include-in-header:
      text: |
        \usepackage{longtable}
        \usepackage{booktabs}
        \usepackage{array}
        \usepackage{etoolbox}
        \pretocmd{\tableofcontents}{\clearpage}{}{}
    toc-title: "Table of Contents"
execute:
  echo: false
  warning: false
  message: false
  error: false
jupyter: python3
---

\clearpage

## Introduction  

Building on the insights from the predictive churn analysis, this report presents the prescriptive optimization phase of the PlaylistPro customer retention project.  
In the predictive stage, models such as logistic regression, random forest, and XGBoost were used to identify the primary drivers of churn and estimate each customer's churn probability. XGBoost emerged as the best-performing model with an AUC of 0.94, revealing that factors such as subscription type, customer service interactions, listening hours, and song skip rate were the most influential predictors of churn.  

The optimization phase uses these predictive results as direct inputs for decision-making. Through a Mixed-Integer Linear Programming (MILP) framework implemented with the Gurobi solver, the model determines the optimal combination of retention actions for each customer. The objective is to maximize expected retained customer lifetime value while staying within PlaylistPro's budget, operational capacity, and fairness constraints.  

This report demonstrates how predictive analytics and optimization can work together to create an actionable strategy that balances business goals and operational feasibility. The analysis also explores budget sensitivity to determine the spending range that delivers the best return on investment, providing PlaylistPro with a data-driven foundation for future retention planning.

```{python}
import warnings
import sys
import io
from contextlib import redirect_stdout

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from music_streaming_retention_75k import MusicStreamingRetentionOptimizer

# Suppress warnings
warnings.filterwarnings("ignore")
pd.set_option("display.max_columns", None)
pd.set_option("display.precision", 2)
pd.set_option("display.float_format", lambda x: f"${x:,.2f}" if abs(x) > 1 else f"{x:.4f}")
```

---

## 1. DECISION VARIABLES

### 1.1 Mathematical Definition

The decision variable *x[i,k]* represents **whether or not a specific customer receives a particular retention action**. In simple terms, the optimization model evaluated every possible combination of customers and marketing actions, then decides which ones to execute.

Each *x[i,k]* acts like an on/off switch:

  - A value of **1** means the action is selected for that customer.

  - A value of **0** means the action is not selected.

This structure ensures that every customer in the campaign can receive **at most one action**, such as a discount offer, personalized recommendation, or no contact at all. The model's role is to determine the best mix of these binary choices so that the campaign's overall goal is acheived efficiently.

**Variable Definition:**

```
x[i,k] ∈ {0, 1}  for all i ∈ I, k ∈ K

Where:
  i ∈ I = {1, 2, ..., 250}     (customer index)
  k ∈ K = {0, 1, 2, ..., 7}    (action index)
  
  x[i,k] = 1  if customer i receives action k
  x[i,k] = 0  otherwise
```

**Example Interpretation:**

- `x[12345, 2] = 1` → Assign "20% Discount Offer" to customer 12345

- `x[67890, 0] = 1` → Assign "No Action" to customer 67890 (do not contact)

- `x[11111, 5] = 1` → Assign "In-App Personalized Offer" to customer 11111



### 1.2 Variable Type

**Type:** Binary (0-1 integer variables)

The binary setup reflects how marketing decisions work in pracitce where a customer either receives a promotion, message, or offer, or they don't. There's no in-between state such as "partially sending" an email or "half-applying" a discount. Using binary variables keep the model consistent with how real campaigns are executed.

### 1.3 Variable Bounds

**Lower Bound:** `x[i,k] ≥ 0` (implicit non-negativity)  
**Upper Bound:** `x[i,k] ≤ 1` (implicit binary constraint)

**Additional Structural Bound:** `Σ[k∈K] x[i,k] ≤ 1` for each customer i

This constraint guarantees that each customer is assigned **no more than one action**.

### 1.4 Model Scale

The optimization model includes **2,000 binary decision variables** based on 250 customers and 8 possible actions. This size fits within the limits of the Gurobi academic license.

At full production scale, applying the same setup to PlaylistPro's complete customer base of 75,000 users would result in **approximately 600,000 binary variables**, which would require a commerical license for requirement.

```{python}
# Create illustrative example of decision variables (compact version)
decision_var_examples = pd.DataFrame({
    'Variable': ['x[12345,0]', 'x[12345,1]', 'x[12345,2]', 'x[67890,0]', 'x[67890,5]'],
    'Cust_ID': [12345, 12345, 12345, 67890, 67890],
    'Action': ['No Action', 'Email', 'Discount', 'No Action', 'In-App'],
    'Value': [0, 0, 1, 1, 0],
    'Result': ['NOT selected', 'NOT selected', 'SELECTED', 'SELECTED', 'NOT selected']
})

decision_var_examples
```

---

## 2. CONSTRAINTS

The optimization model enforces six categories of constraints to ensure realistic, ethical, and operationally feasible solutions. All constraints are expressed as **linear combinations of the decision variables**.

### 2.1 Operational Capacity Constraints (≤ constraints)

#### Budget Constraint
```
Σ[i∈I] Σ[k∈K] c[k] · x[i,k] ≤ B

Where:
  c[k] = cost of action k (dollars)
  B = weekly budget (e.g., $150)
```

This constraint is linear because it multiplies each action's fixed cost *c[k]* by the corresponding binary decision variable *x[i,k]* and then sums these values across all customers and actions. In practical terms, it ensures that the total spending on retention activities remains within the weekly campaign budget, reflecting how PlaylistPro manages marketing costs while staying within financial limits.

#### Email Capacity Constraint
```
Σ[i∈I] Σ[k∈E] x[i,k] ≤ C_email

Where:
  E = {1, 2, 7} (email-based actions)
  C_email = maximum weekly emails (e.g., 120)
```

This constraint limits the total number of emails that can be sent in a given week. It ensures the marketing team stays within operational capacity and avoids overwhelming customers with excessive communication, helping maintain engagement quality and brand trust.

#### In-App/Push Notification Capacity Constraint
```
Σ[i∈I] Σ[k∈P] x[i,k] ≤ C_push

Where:
  P = {5, 6} (in-app and push notification actions)
  C_push = maximum weekly push/in-app messages (e.g., 100)
```

This constraint limits how many in-app messages and push notifications can be sent each week. It ensures the product team stays within technical and engagement limits, maintaining a balanced communication strategy that avoids excessive notifications and preserves a positive user experience.

### 2.2 One Action Per Customer Constraint (≤ constraint)

```
Σ[k∈K] x[i,k] ≤ 1  for all i ∈ I
```

This constraint ensures that each customer is assigned only one retention action, such as an email, discount, or in-app message. Allowing multiple actions for the same customer would lead to redundant communication, inconsistent experiences, and unnecessary campaign costs.

### 2.3 Policy Constraints 

Policy constraints are important because they incorporate strategic or ethical business rules that go beyond pure cost optimization. They ensure that the model's recommendations align with PlaylistPro's retention goals and customer relationship policies, maintaining a balance between profitability and fairness.

#### Minimum High-Risk Coverage
```
Σ[i∈H] Σ[k∈K, k>0] x[i,k] ≥ α · |H|

Where:
  H = {i | p[i] > 0.5} (high-risk customers with churn probability > 50%)
  α = minimum coverage rate (e.g., 0.60)
```

In this specific case, the constraint requires that at least 60 percent of high-risk customers receive some form of proactive outreach. It prevents the optimization model from focusing solely on high-value users while neglecting those most likely to churn, ensuring that retention efforts remain inclusive and consistent with company policy.

#### Minimum Premium Customer Coverage
```
Σ[i∈P] Σ[k∈K, k>0] x[i,k] ≥ β · |P|

Where:
  P = {i | subscription_type[i] = 'Premium'} (Premium subscribers)
  β = minimum coverage rate (e.g., 0.40)
```

This constraint guarantees that at least 40 percent of Premium customers receive targeted retention actions. It reflects the company's priority to provide consistent engagement and special attention to its most valuable subscribers, reinforcing loyalty among users who contribute the highest share of revenue.


### 2.4 Advanced Policy Constraints

These constraints guide how the optimizer allocates actions across customers. They ensure the model stays balanced, fair, and aligned with PlaylistPro's marketing goals.

#### Action Saturation Cap 
```
Σ[i∈I] x[i,k] ≤ γ · |I|  for each action k ∈ K

Where:
   γ = maximum saturation rate (e.g., 0.50)
```

This constraint limits any single action to a maximum of 50 percent of all customers. For example, if there are 250 customers, no more than 125 can receive the same offer, such as a discount email or push notification. This rule prevents the optimizer from relying too heavily on one low-cost action and promotes a more balanced campaign mix. As a result, PlaylistPro can maintain engagement variety across channels and tailor outreach strategies to different user segments.

#### Fairness Coverage Floor 
```
Σ[i∈S] Σ[k∈K, k>0] x[i,k] ≥ δ · |S|  for each segment S ∈ {Premium, Free, Family, Student}

Where:
   δ = minimum segment coverage rate (e.g., 0.15)
```

This constraint ensures that every subscription segment receives a minimum level of outreach, set at 15 percent in this case. For example, at least 15 percent of Free, Premium, Family, and Student users must be included in the campaign. This prevents the optimizer from allocating all resources to higher-value groups and helps maintain fairness across customer types. It safeguards against algorithmic bias and ensures PlaylistPro's retention strategy remains inclusive and aligned with its broader customer relationship goals.

### 2.5 Redundant Constraints

During model development, several constraints were identified as unnecessary because their effects were already enforced by other parts of the formulation.

First, individual customer budget limits were removed since the global campaign budget, combined with the one-action-per-customer rule, already prevents overspending on any single user. Second, separate constraints for each action type were consolidated, as the unified email and push capacity limits capture all relevant communication channels without double-counting. Finally, explicit non-negativity constraints were excluded because the binary definition of the decision variables inherently ensures all values remain non-negative.

These refinements made the model cleaner, more efficient, and easier to interpret without changing its logic or outcomes.

```{python}
# Create constraint summary table with simplified columns
constraint_summary = pd.DataFrame({
    'Constraint': [
        'Budget', 
        'Email Capacity', 
        'Push/In-App Capacity',
        'One Action Per Customer',
        'Min High-Risk Coverage',
        'Min Premium Coverage',
        'Action Saturation Cap',
        'Fairness Coverage Floor'
    ],
    'Type': ['≤', '≤', '≤', '≤', '≥', '≥', '≤', '≥'],
    'Count': [1, 1, 1, 250, 1, 1, 8, 4],
    'Purpose': [
        'Limit spending',
        'Prevent fatigue',
        'Team capacity',
        'One per customer',
        'Cover high-risk',
        'Cover Premium',
        'Force diversity',
        'Fair segments'
    ]
})

constraint_summary
```

**Total Constraints:** 267 (1 + 1 + 1 + 250 + 1 + 1 + 8 + 4)

---

## 3. OBJECTIVE FUNCTION

### 3.1 Objective Type

The objective of the optimization model is to **maximize the total expected net value** generated from the retention campaign. In simple terms, the model determines which customer-action assignments create the highest return once both the customer's lifetime value and the cost of each marketing action are considered.

### 3.2 Mathematical Formulation

```
Maximize: Z = Σ[i∈I] Σ[k∈K] (p[i] · u[k] · v[i] - c[k]) · x[i,k]

Where:
  p[i] = churn probability for customer i (from XGBoost predictions, range: 0.005 to 0.998)
  u[k] = uplift (effectiveness) of action k (e.g., 0.08 = 8% churn reduction)
  v[i] = customer lifetime value (CLV) of customer i (range: $120 to $480)
  c[k] = cost of action k (range: $0 to $30)
  x[i,k] = binary decision variable
```

### 3.3 Linearity

The objective function is a **linear combination** of the binary decision variables x[i,k], with coefficients (p[i] × u[k] × v[i] - c[k]) computed from the data. This means the optimization problem remains a **linear program**, which allows it to be solved efficiently using Gurobi.

### 3.4 Economic Interpretation

For each customer-action pair, we calculate the **expected marginal contribution** to campaign value:

```
Net Value[i,k] = (Churn Probability) × (Action Effectiveness) × (Customer Value) - (Action Cost)
                = p[i] × u[k] × v[i] - c[k]
```

This represents how much value is expected from targeting a specific customer with a given action after accounting for cost.

Intuitively, the model favors customer-action pairs that create the most value for the business. Customers who are **likely to churn**, **valuable if retained**, and have an **effective yet low-cost action** available generate the highest expected return. For example, offering a small discount to a premium user at high risk of leaving produces more benefit than targeting a low-risk, low-value user. The optimizer automatically identifies and prioritizes such high-impact opportunities.

### 3.5 Worked Example

**Customer 12345: Premium subscriber**
- p[12345] = 0.72 (72% churn risk)
- v[12345] = $240 (12-month CLV)

**Action k=2: 20% Discount Offer**
- u[2] = 0.15 (15% churn reduction)
- c[2] = $20 (one-month discount cost)

**Expected Net Value:**
```
Net Value = 0.72 × 0.15 × $240 - $20
          = $25.92 - $20
          = $5.92
```

Offering a discount to this customer is expected to generate $5.92 in net value. If x[12345, 2] = 1 (assign discount to customer 12345), this contributes +$5.92 to the objective function.

---

## 4. BASELINE OPTIMIZATION RUN

In this section, the optimization model is executed under the defined baseline constraints to evaluate its real-world performance. The results establish a reference point for assessing how effectively the model allocates retention actions and resources within operational limits.

```{python}
# Initialize optimizer and load data
with redirect_stdout(io.StringIO()):
    optimizer = MusicStreamingRetentionOptimizer()
    optimizer.load_data(
        churn_file='prediction_250.csv',
        customer_features_file='test_250.csv',
        actions_file=None
    )
    
    baseline_constraints = {
        'weekly_budget': 150,
        'email_capacity': 120,
        'call_capacity': 100,
        'min_high_risk_pct': 0.60,
        'min_premium_pct': 0.40,
        'max_action_pct': 0.50,
        'min_segment_coverage_pct': 0.15
    }
    
    optimizer.set_constraints(baseline_constraints)
    optimizer.optimize()

baseline_results = optimizer.results
```

```{python}
# Extract and display baseline KPIs
kpis = baseline_results['kpis']

baseline_kpi_df = pd.DataFrame({
    'Metric': [
        'Customers Treated',
        'Total Weekly Spend',
        'Expected Retained CLV',
        'Net Value',
        'ROI',
        'Expected Churn Reduction',
        'Budget Utilization'
    ],
    'Value': [
        f"{kpis['customers_treated']} / 250",
        f"${kpis['total_spend']:,.2f}",
        f"${kpis['expected_retained_clv']:,.2f}",
        f"${kpis['net_value']:,.2f}",
        f"{kpis['roi']:.1f}%",
        f"{kpis['expected_churn_reduction']:.1f} customers",
        f"{(kpis['total_spend'] / 150 * 100):.1f}%"
    ]
})

baseline_kpi_df
```

The baseline optimization achieved **full budget utilization**, meaning the model efficiently allocated the entire $150 weekly retention budget. Out of 250 customers, **75 were selected for targeted interventions**, representing 30 percent of the total base.

The optimized campaign is expected to **retain $3,628.82 in customer lifetime value (CLV)**, generating a **net gain of $3,478.82** after accounting for action costs. This corresponds to an expectionaly high **return on investment (ROI) of 2,319.2%**, demonstrating that the chosen mix of actions delivers substantial value relative to the spend.

In practical terms, the campaign is expected **prevent churn for about five customers** in this sample. Overall these results confirm that the optimization model effectively identifies high-impact customers and actions, maximizing retention value while remaining within operational limits.

```{python}
# Constraint binding analysis
assignments = baseline_results['assignments']

# Calculate constraint usage
num_emails = len(assignments[assignments['channel'].isin(['email'])])
num_push = len(assignments[assignments['channel'].isin(['in_app', 'push'])])
num_high_risk = (optimizer.customers_df['risk_segment'] == 'high_risk').sum()
high_risk_treated = len(assignments[assignments['risk_segment'] == 'high_risk'])
num_premium = (optimizer.customers_df['subscription_type'] == 'Premium').sum()
premium_treated = len(assignments[assignments['subscription_type'] == 'Premium'])

binding_df = pd.DataFrame({
    'Constraint': [
        'Budget',
        'Email Capacity',
        'Push/In-App Capacity',
        'High-Risk Coverage (≥60%)',
        'Premium Coverage (≥40%)'
    ],
    'Limit/Required': [
        '$150',
        '120',
        '100',
        f'{int(num_high_risk * 0.6)}',
        f'{int(num_premium * 0.4)}'
    ],
    'Used/Achieved': [
        f'${kpis["total_spend"]:.2f}',
        f'{num_emails}',
        f'{num_push}',
        f'{high_risk_treated}',
        f'{premium_treated}'
    ],
    'Utilization': [
        f'{(kpis["total_spend"] / 150 * 100):.1f}%',
        f'{(num_emails / 120 * 100):.1f}%',
        f'{(num_push / 100 * 100):.1f}%',
        f'{(high_risk_treated / (num_high_risk * 0.6) * 100):.1f}%',
        f'{(premium_treated / (num_premium * 0.4) * 100):.1f}%'
    ],
    'Status': [
        'Binding' if kpis["total_spend"] >= 145 else 'Slack',
        'Binding' if num_emails >= 115 else 'Slack',
        'Binding' if num_push >= 95 else 'Slack',
        'Satisfied' if high_risk_treated >= num_high_risk * 0.6 else 'Violated',
        'Satisfied' if premium_treated >= num_premium * 0.4 else 'Violated'
    ]
})

binding_df
```

The constraint binding analysis examines which operational and policy limits were fully utilized (binding) and which had unused capacity (slack). This helps assess whether the optimization run efficiently used available resources or if certain constraints restricted the solution.

In the baseline scenario, the budget constraint was binding, meaning the full $150 weekly budget was spent. This indicates the optimizer allocated every available dollar to maximize retention value. Both email and push/in-app capacities remained slack, suggesting additional communication volume could be supported without exceeding limits.

However, the high-risk coverage and premium customer coverage constraints were slightly violated, with achieved rates of 96.6% and 96.8% against the 60% and 40% targets respectively. These small deviations suggest that the optimizer reached near-satisfaction but was limited by other interacting constraints such as the overall budget and maximum action saturation.

Overall, the analysis shows that the optimizer efficiently used the budget while staying close to key policy thresholds, highlighting areas where relaxing certain limits (for example, increasing the budget or reducing action caps) could improve future campaign coverage.

```{python}
# Action mix distribution by subscription segment
action_segment_crosstab = pd.crosstab(
    assignments['subscription_type'],
    assignments['action_name'],
    margins=True,
    margins_name='Total'
)

action_segment_crosstab
```

The table summarizes how retention actions were distributed across different subscription segments. In this baseline run, the optimizer selected a single action type — personalized email — for all treated customers.

Among the 75 customers who received an intervention:

- **Premium users:** 24 were targeted, reflecting focus on high-value customers.

- **Family users:** 19 received actions, showing balanced treatment among group-based subscribers.

- **Student users:** 17 were included, maintaining engagement in a lower-value but important growth segment.

- **Free users:** 15 were targeted, ensuring continued inclusion of entry-level customers.

Although only one action type was used in this scenario, the distribution across segments indicates that the optimizer respected fairness and coverage goals by proportionally reaching all customer types. In future runs with expanded action catalogs, this analysis will help evaluate whether the optimizer diversifies campaign strategies across multiple communication channels.

---

## 5. SENSITIVITY ANALYSIS - BUDGET VARIATION

This section examines how changes in the weekly marketing budget affect campaign performance and model behavior. The goal is to help PlaylistPro determine the most efficient spending level for customer retention.

The analysis increases the weekly budget from **$150** to **$1,000** and tracks how key outcomes such as total net value, return on investment, and constraint utilization respond to higher spending. This approach identifies the point where diminishing returns begin and shows which operational limits, such as email capacity or coverage requirements, start to restrict further gains.

By comparing results across different budget levels, the analysis highlights the budget range that delivers the greatest retention value without unnecessary cost.

```{python}
# Budget sensitivity analysis
budget_levels = [150, 175, 200, 225, 250, 300, 350, 400, 500, 600, 750, 1000]

sensitivity_results = []

for budget in budget_levels:
    try:
        with redirect_stdout(io.StringIO()):
            opt = MusicStreamingRetentionOptimizer()
            opt.load_data(
                churn_file='prediction_250.csv',
                customer_features_file='test_250.csv',
                actions_file=None
            )
            
            constraints = {
                'weekly_budget': budget,
                'email_capacity': 120,
                'call_capacity': 100,
                'min_high_risk_pct': 0.60,
                'min_premium_pct': 0.40,
                'max_action_pct': 0.50,
                'min_segment_coverage_pct': 0.15
            }
            
            opt.set_constraints(constraints)
            opt.optimize()
        
        if 'kpis' not in opt.results or 'assignments' not in opt.results:
            sensitivity_results.append({
                'Budget': budget,
                'Customers_Treated': 0,
                'Total_Spend': 0,
                'Net_Value': 0,
                'ROI': 0,
                'Expected_Churn_Reduction': 0,
                'Email_Used': 0,
                'Push_Used': 0,
                'Budget_Binding': 'N/A',
                'Email_Binding': 'N/A'
            })
            opt.cleanup()
            continue
        
        kpis_sens = opt.results['kpis']
        assignments_sens = opt.results['assignments']
        
        num_emails_sens = len(assignments_sens[assignments_sens['channel'].isin(['email'])])
        num_push_sens = len(assignments_sens[assignments_sens['channel'].isin(['in_app', 'push'])])
        
        sensitivity_results.append({
            'Budget': budget,
            'Customers_Treated': kpis_sens['customers_treated'],
            'Total_Spend': kpis_sens['total_spend'],
            'Net_Value': kpis_sens['net_value'],
            'ROI': kpis_sens['roi'],
            'Expected_Churn_Reduction': kpis_sens['expected_churn_reduction'],
            'Email_Used': num_emails_sens,
            'Push_Used': num_push_sens,
            'Budget_Binding': 'Yes' if kpis_sens['total_spend'] >= budget * 0.95 else 'No',
            'Email_Binding': 'Yes' if num_emails_sens >= 115 else 'No'
        })
        
        opt.cleanup()
        
    except Exception as e:
        sensitivity_results.append({
            'Budget': budget,
            'Customers_Treated': 0,
            'Total_Spend': 0,
            'Net_Value': 0,
            'ROI': 0,
            'Expected_Churn_Reduction': 0,
            'Email_Used': 0,
            'Push_Used': 0,
            'Budget_Binding': 'Error',
            'Email_Binding': 'Error'
        })

sensitivity_df = pd.DataFrame(sensitivity_results)
```

```{python}
# Display sensitivity analysis results - select key columns only
display_df = sensitivity_df[['Budget', 'Customers_Treated', 'Total_Spend', 'Net_Value', 'ROI']].copy()
display_df.columns = ['Budget', 'Customers', 'Spend', 'Net Value', 'ROI %']
display_df['Spend'] = display_df['Spend'].apply(lambda x: f'${x:,.0f}')
display_df['Net Value'] = display_df['Net Value'].apply(lambda x: f'${x:,.0f}')
display_df['ROI %'] = display_df['ROI %'].apply(lambda x: f'{x:.0f}')

display_df
```

The budget sensitivity results show how campaign performance changes as the weekly budget increases from $150 to $1,000. The findings indicate that additional budget allows more customers to be treated and increases both total net value and expected churn reduction, though at a decreasing rate.

Between **$150 and $400**, net value grows rapidly, reflecting strong early returns from reaching additional high-impact customers. Beyond **$500**, the rate of improvement slows, suggesting **diminishing returns** as most high-value opportunities are already captured.

The **ROI** drops from over 2300 percent at $150 to around 1100 percent at $1,000, confirming that larger budgets yield lower efficiency even as total value rises. Throughout all runs, the **budget constraint remains binding**, indicating that the optimizer consistently used the full amount available, while the **email capacity** never became restrictive.

Overall, the optimal range appears to fall between **$300 and $500** per week, where PlaylistPro achieves strong returns before diminishing gains become significant.

---

## 6. OPTIMIZATION RESULTS VISUALIZATIONS

Visual representations of the optimization results help identify patterns, optimal operating ranges, and business insights.

```{python}
#| fig-cap: "Budget Sensitivity: Net Value vs Weekly Budget"

fig = go.Figure()
fig.add_trace(go.Scatter(
    x=sensitivity_df['Budget'],
    y=sensitivity_df['Net_Value'],
    mode='lines+markers',
    name='Net Value',
    line=dict(color='#1DB954', width=3),
    marker=dict(size=8)
))

fig.add_vrect(
    x0=150, x1=250,
    fillcolor="green", opacity=0.1,
    layer="below", line_width=0,
    annotation_text="Optimal Range",
    annotation_position="top left"
)

fig.update_layout(
    title='Budget Sensitivity: Net Value vs Weekly Budget ($150-$1,000)',
    xaxis_title='Weekly Budget ($)',
    yaxis_title='Expected Net Value ($)',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz1_budget_netvalue.png", width=800, height=500, scale=2)
```

![Budget Sensitivity: Net Value vs Weekly Budget](visualizations/viz1_budget_netvalue.png)


The chart illustrates how the expected net value rises as the weekly budget increases.  
The curve's turning point, or "knee," appears around the **$200 to $300** range, marking the budget level where additional spending begins to yield smaller incremental gains.  

Beyond approximately **$400 to $500**, the curve flattens, indicating that higher budgets produce only minor improvements in total value.  
This suggests that allocating funds within the **$250 to $400** range delivers the best balance between cost efficiency and retention impact.

```{python}
#| fig-cap: "Budget Sensitivity: ROI vs Weekly Budget"

fig = go.Figure()
fig.add_trace(go.Scatter(
    x=sensitivity_df['Budget'],
    y=sensitivity_df['ROI'],
    mode='lines+markers',
    name='ROI',
    line=dict(color='#E74C3C', width=3),
    marker=dict(size=8),
    fill='tozeroy',
    fillcolor='rgba(231, 76, 60, 0.1)'
))

fig.add_hline(
    y=400,
    line_dash="dash",
    line_color="gray",
    annotation_text="400% ROI Target"
)

fig.update_layout(
    title='Budget Sensitivity: ROI vs Weekly Budget (Diminishing Returns)',
    xaxis_title='Weekly Budget ($)',
    yaxis_title='Return on Investment (%)',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz2_budget_roi.png", width=800, height=500, scale=2)
```

![Budget Sensitivity: ROI vs Weekly Budget](visualizations/viz2_budget_roi.png)


The chart shows that return on investment (ROI) declines as the weekly budget increases, reflecting a typical pattern of diminishing returns.  
At lower budgets, such as the $150 baseline, the optimizer focuses on the most profitable customer–action pairs, producing exceptionally high ROI.  
As the budget expands toward $1,000, the optimizer must target customers with lower value or less effective actions, which reduces efficiency.  

The results suggest that the optimal budget is one that balances **high ROI with adequate customer coverage**, typically within the $250 to $400 range.

```{python}
#| fig-cap: "Budget Sensitivity: Customer Coverage"

fig = go.Figure()
fig.add_trace(go.Scatter(
    x=sensitivity_df['Budget'],
    y=sensitivity_df['Customers_Treated'],
    mode='lines+markers',
    name='Customers Treated',
    line=dict(color='#3498DB', width=3),
    marker=dict(size=8)
))

fig.add_hline(
    y=250,
    line_dash="dash",
    line_color="gray",
    annotation_text="Total Customers (250)"
)

fig.update_layout(
    title='Budget Sensitivity: Customer Coverage vs Weekly Budget',
    xaxis_title='Weekly Budget ($)',
    yaxis_title='Number of Customers Treated',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz3_budget_coverage.png", width=800, height=500, scale=2)
```

![Budget Sensitivity: Customer Coverage](visualizations/viz3_budget_coverage.png)


Customer coverage expands rapidly at lower budget levels, as more customers can be targeted within the available resources.  
However, the growth begins to slow once the budget reaches approximately **$300 to $400**, when operational limits such as email capacity and action saturation start to restrict additional outreach.  

Beyond this point, higher spending produces only minor increases in the number of customers treated, suggesting that most high-value opportunities have already been captured. This plateau signals that further optimization should focus on **improving action effectiveness** rather than simply increasing the budget.

```{python}
#| fig-cap: "Action Mix Distribution (Baseline)"

action_counts = baseline_results['assignments']['action_name'].value_counts()

fig = go.Figure()
fig.add_trace(go.Bar(
    x=action_counts.index,
    y=action_counts.values,
    marker_color='#2ECC71'
))

fig.update_layout(
    title='Action Mix Distribution (Baseline: $150 Budget)',
    xaxis_title='Retention Action',
    yaxis_title='Number of Customers',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz4_action_mix.png", width=800, height=500, scale=2)
```

![Action Mix Distribution](visualizations/viz4_action_mix.png)


The baseline run shows that all 75 treated customers received personalized emails, indicating that this channel delivered the best cost-to-impact ratio within the $150 budget. Future scenarios with higher budgets or more available actions can introduce greater channel diversity as other interventions become cost-effective.

```{python}
#| fig-cap: "Action Distribution by Subscription Segment"

segment_action = baseline_results['assignments'].groupby(['subscription_type', 'action_name']).size().unstack(fill_value=0)

fig = go.Figure()
for action in segment_action.columns:
    fig.add_trace(go.Bar(
        name=action,
        x=segment_action.index,
        y=segment_action[action]
    ))

fig.update_layout(
    title='Action Distribution by Subscription Segment (Baseline)',
    xaxis_title='Subscription Type',
    yaxis_title='Number of Customers',
    barmode='stack',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz5_segment_action.png", width=800, height=500, scale=2)
```

![Action Distribution by Subscription Segment](visualizations/viz5_segment_action.png)


All subscription segments received treatment, meeting the fairness coverage requirement. Premium and other high-value users were prioritized for targeted actions, reflecting the optimizer's focus on retaining customers who deliver the greatest long-term value.

```{python}
#| fig-cap: "Treatment Concentration: Risk Tier vs Subscription Type"

heatmap_data = pd.crosstab(
    baseline_results['assignments']['risk_segment'],
    baseline_results['assignments']['subscription_type']
)

fig = go.Figure(data=go.Heatmap(
    z=heatmap_data.values,
    x=heatmap_data.columns,
    y=heatmap_data.index,
    colorscale='YlGn',
    text=heatmap_data.values,
    texttemplate='%{text}',
    textfont={"size": 14}
))

fig.update_layout(
    title='Treatment Concentration: Risk Tier vs Subscription Type',
    xaxis_title='Subscription Type',
    yaxis_title='Risk Tier',
    template='plotly_white',
    height=500
)

fig.write_image("visualizations/viz6_heatmap.png", width=800, height=500, scale=2)
```

![Treatment Concentration: Risk Tier vs Subscription Type](visualizations/viz6_heatmap.png)


The optimizer targets customers across both high-risk and medium-risk tiers while maintaining representation across all subscription types. Premium and Family users receive the most balanced treatment, reflecting their higher lifetime value and the fairness constraints that ensure no segment is overlooked. The model's concentration in the high-risk tier shows that it effectively directs resources toward customers most likely to churn.

```{python}
#| fig-cap: "Net Value Breakdown (Baseline)"

baseline_kpis = baseline_results['kpis']
categories = ['Expected<br>Retained CLV', 'Campaign<br>Cost', 'Net Value']
values = [baseline_kpis['expected_retained_clv'], -baseline_kpis['total_spend'], baseline_kpis['net_value']]
colors = ['#2ECC71', '#E74C3C', '#3498DB']

fig = go.Figure()
fig.add_trace(go.Bar(
    x=categories,
    y=values,
    marker_color=colors,
    text=[f'${abs(v):,.2f}' for v in values],
    textposition='outside'
))

fig.add_hline(y=0, line_color='black', line_width=1)

fig.update_layout(
    title='Net Value Breakdown: Retained CLV - Campaign Cost (Baseline)',
    yaxis_title='Value ($)',
    template='plotly_white',
    height=500,
    showlegend=False
)

fig.write_image("visualizations/viz7_netvalue_breakdown.png", width=800, height=500, scale=2)
```

![Net Value Breakdown](visualizations/viz7_netvalue_breakdown.png)


The baseline scenario generated an expected retained customer lifetime value (CLV) of **$3,628.82**, against a campaign cost of **$150**.  
This results in a **net value of $3,478.82**, showing that the optimizer produced substantial financial gains relative to the investment.  
The breakdown confirms that even with minimal spending, the model effectively targets high-impact customers whose retention delivers strong returns.

```{python}
#| fig-cap: "Customer Segmentation: Churn Probability vs CLV"

all_customers = optimizer.customers_df.copy()
treated_ids = set(baseline_results['assignments']['customer_id'])
all_customers['treated'] = all_customers['customer_id'].isin(treated_ids)

fig = go.Figure()

# Untreated customers
untreated = all_customers[~all_customers['treated']]
fig.add_trace(go.Scatter(
    x=untreated['p'],
    y=untreated['v'],
    mode='markers',
    name='Not Treated',
    marker=dict(color='#95A5A6', size=8, opacity=0.4)
))

# Treated customers
treated = all_customers[all_customers['treated']]
fig.add_trace(go.Scatter(
    x=treated['p'],
    y=treated['v'],
    mode='markers',
    name='Treated',
    marker=dict(color='#2ECC71', size=8, opacity=0.6)
))

# Add quadrant lines
median_clv = all_customers['v'].median()
fig.add_hline(y=median_clv, line_dash="dash", line_color="lightgray", opacity=0.7)
fig.add_vline(x=0.5, line_dash="dash", line_color="lightgray", opacity=0.7)

fig.update_layout(
    title='Customer Segmentation: Churn Probability vs CLV (Treatment Allocation)',
    xaxis_title='Churn Probability',
    yaxis_title='Customer Lifetime Value ($)',
    template='plotly_white',
    height=600,
    xaxis=dict(range=[0, 1])
)

fig.write_image("visualizations/viz8_scatter_churn_clv.png", width=800, height=600, scale=2)
```

![Customer Segmentation: Churn Probability vs CLV](visualizations/viz8_scatter_churn_clv.png)


The scatter plot shows how the optimizer allocates treatments based on customer churn probability and lifetime value (CLV).  
Most treated customers cluster in the upper-right region, representing those with both **high churn risk and high lifetime value**.  
This confirms that the model prioritizes interventions where retention impact is greatest, focusing resources on valuable customers most likely to leave.  
Lower-value or low-risk users are largely untreated, which aligns with an efficient and targeted retention strategy.

---

## 7. BUSINESS IMPACT ANALYSIS

This section quantifies the business impact of the optimization model compared to alternative approaches.

```{python}
# Top 10 Highest Impact Customer Assignments
assignments_with_net_value = baseline_results['assignments'].copy()

if 'net_value' not in assignments_with_net_value.columns:
    if all(col in assignments_with_net_value.columns for col in ['churn_prob', 'uplift', 'clv', 'cost']):
        assignments_with_net_value['net_value'] = (
            assignments_with_net_value['churn_prob'] * 
            assignments_with_net_value['uplift'] * 
            assignments_with_net_value['clv'] - 
            assignments_with_net_value['cost']
        )

# Select minimal columns for compact display
if 'p' in assignments_with_net_value.columns:
    cols_to_select = ['subscription_type', 'p', 'v', 'net_value']
else:
    cols_to_select = ['subscription_type', 'churn_prob', 'clv', 'net_value']

top_10 = assignments_with_net_value.nlargest(10, 'net_value')[cols_to_select].reset_index(drop=True)
top_10.index = range(1, 11)
top_10.index.name = 'Rank'

top_10_display = top_10.copy()

# Format columns
if 'p' in top_10_display.columns:
    top_10_display['p'] = top_10_display['p'].apply(lambda x: f'{x:.0%}')
    top_10_display['v'] = top_10_display['v'].apply(lambda x: f'${x:.0f}')
    top_10_display.columns = ['Segment', 'Churn', 'CLV', 'Net Value']
else:
    top_10_display['churn_prob'] = top_10_display['churn_prob'].apply(lambda x: f'{x:.0%}')
    top_10_display['clv'] = top_10_display['clv'].apply(lambda x: f'${x:.0f}')
    top_10_display.columns = ['Segment', 'Churn', 'CLV', 'Net Value']

top_10_display['Net Value'] = top_10_display['Net Value'].apply(lambda x: f'${x:.2f}')

top_10_display
```

### Top 10 Highest-Impact Customer Assignments  

The table lists the ten customer–action pairs that generated the highest expected net value in the baseline optimization run.  
Most of these customers belong to the **Family** and **Premium** segments, which aligns with their higher lifetime value and stronger response to retention offers.  

All top-performing actions are **personalized emails**, confirming this channel's effectiveness within the current cost structure.  
These customers exhibit both **high churn probability (above 85%)** and **high CLV**, resulting in significant gains from even low-cost interventions.  

This finding illustrates that the model successfully identifies and prioritizes customers with the greatest financial impact, allowing PlaylistPro to focus resources where retention yields the highest return.

```{python}
# Fairness Analysis: Coverage Rates by Subscription Segment
segment_coverage = []

for segment in ['Premium', 'Free', 'Family', 'Student']:
    total_in_segment = (optimizer.customers_df['subscription_type'] == segment).sum()
    treated_in_segment = (baseline_results['assignments']['subscription_type'] == segment).sum()
    coverage_rate = treated_in_segment / total_in_segment if total_in_segment > 0 else 0
    min_required = int(total_in_segment * 0.15)
    
    segment_coverage.append({
        'Segment': segment,
        'Total_Customers': total_in_segment,
        'Treated': treated_in_segment,
        'Coverage_Rate': coverage_rate,
        'Minimum_Required_15%': min_required,
        'Status': 'Satisfied' if treated_in_segment >= min_required else 'Violated'
    })

fairness_df = pd.DataFrame(segment_coverage)
fairness_display = fairness_df.copy()
fairness_display['Coverage_Rate'] = fairness_display['Coverage_Rate'].apply(lambda x: f'{x:.1%}')

fairness_display
```

The fairness analysis confirms that all four subscription segments met the minimum 15 percent coverage requirement.  
Coverage ranged from **24.2 percent for Free users** to **38.7 percent for Premium users**, well above the threshold in every case.  

This result shows that the optimizer distributed outreach actions fairly across all customer types, ensuring no segment was excluded from the campaign.  
Premium and Family users received the highest proportional treatment, reflecting their stronger contribution to overall customer value, while Free and Student users were still adequately represented to maintain inclusivity.

## Summary and Recommendations  

The PlaylistPro retention optimization model combines predictive analytics with mathematical optimization to determine the most effective customer outreach strategy.  
By integrating churn probabilities, customer lifetime value, and action costs, the model identifies which customers to target and how to allocate the weekly retention budget for maximum financial impact.  

The baseline run demonstrated that the model efficiently utilized the $150 budget, treating 75 customers and generating a net value of $3,478.82 with an ROI exceeding 2,300 percent. Treated customers were concentrated among high-risk and high-value users, especially within the Premium and Family segments. All subscription segments met the required 15 percent fairness floor, confirming equitable treatment across the customer base. Personalized email emerged as the most cost-effective channel in this setup.  

Sensitivity analysis showed that while increasing the weekly budget leads to higher retained value, the rate of improvement declines sharply beyond $400 to $500. The results indicate that an optimal spending range of $250 to $400 per week offers the best trade-off between cost and retention performance.  

Overall, the optimization model proved effective at prioritizing high-impact customers, respecting operational limits, and ensuring fairness. PlaylistPro can now apply this framework to guide weekly campaign planning, gradually expand its action catalog, and fine-tune predictive inputs through ongoing experimentation. Doing so will help maintain high retention efficiency while maximizing customer lifetime value in a sustainable and data-driven way.

In addition to that, a self-service dashboard has also been deployed for managerial use cases which can be explored at: https://retention-optimizer-7jrnqgd3bkcth2ebhmv8ua.streamlit.app/

